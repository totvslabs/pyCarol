{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1><center>Data Ingestion</center></h1>\n",
    "\n",
    "In this tutorial we explore how to import the Boston House Prices dataset from scikit learn and load it to the Carol platform."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Installing required packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Appart from the well known pandas an numpy libraries we are going to use:\n",
    " - sklearn: popular machine learning library comprising datasets, preprocessing and machine learning models.\n",
    " - pycarol: TOTVS library developed to assist on the data management for Carol platform."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install pycarol"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Fetching data from source"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading data from scikit learn and storing it on a dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.datasets import load_boston\r\n",
    "\r\n",
    "# Loading the dataset from Scikit Learn\r\n",
    "boston_dataset = load_boston()\r\n",
    "\r\n",
    "# Composing the column names\r\n",
    "column_names = list(boston_dataset['feature_names']) + ['target']\r\n",
    "\r\n",
    "# Creating a dataframe\r\n",
    "boston_dataframe = pd.DataFrame(data= np.c_[boston_dataset['data'], boston_dataset['target']],\r\n",
    "columns=column_names)\r\n",
    "\r\n",
    "# Using the row number as a primary key\r\n",
    "boston_dataframe[\"sample\"] = boston_dataframe.index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking a sample of the data to make sure data is correct."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "boston_dataframe.sample(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "349  0.02899  40.0   1.25   0.0  0.429  6.939  34.5  8.7921  1.0  335.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  sample  \n",
       "349     19.7  389.85   5.89    26.6     349  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.02899</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>6.939</td>\n",
       "      <td>34.5</td>\n",
       "      <td>8.7921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>389.85</td>\n",
       "      <td>5.89</td>\n",
       "      <td>26.6</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Sending data to carol"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by defining a connection to the carol platform. To make the connection, though, we need to setup the security authorization to the environment, which is made through the __access token__.\n",
    "\n",
    "On this example we are simply passing the credentials directly through the code, which is not the best approach for long term solution, specially if this code needs to go through version control servers. A better solution is to store these credentials in expernal files, preferably encrypted, and load them at run time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from pycarol import Carol, Staging, ApiKeyAuth\r\n",
    "\r\n",
    "# =================== AUTHENTICATION ON CAROL ===================\r\n",
    "# Currently set to: Juvenal Jos√© Duarte\r\n",
    "connectors = {\"mltutorial\": 'd6XXXXXeX6X3XXXXX75aXXX54XXXX1Xb'}\r\n",
    "conn_tokens = {\"mltutorial\": 'XXXX40566adcXXXXXX54XXaX8X8XXXa2'}\r\n",
    "# ===============================================================\r\n",
    "\r\n",
    "login = Carol(domain=\"mltutorial\",\r\n",
    "        app_name=\"bostonhouseprice\",\r\n",
    "        organization='datascience',\r\n",
    "        auth=ApiKeyAuth(conn_tokens[\"mltutorial\"]),\r\n",
    "        connector_id=connectors[\"mltutorial\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Note__: When running similar code inside a Carol App the authentication may be omitted, since it can be infereed through the user running the app. The simplified code for apps would be as below. Even domain, app_name and organization parameters can be supressed when running inside apps, in that case they will be retrieved from the environment the app is running on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "''' Simplified version for when running it inside an carol app\r\n",
    "login = Carol(domain=\"mltutorial\",\r\n",
    "        app_name=\"bostonhouseprice\",\r\n",
    "        organization='datascience')\r\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can go on and send the table stored on the dataframe to carol stagings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "staging = Staging(login)\r\n",
    "\r\n",
    "staging.send_data(\r\n",
    "    # The dataset itself\r\n",
    "    data=boston_dataframe, \r\n",
    "    \r\n",
    "    # The field which compose the primary key\r\n",
    "    crosswalk_auto_create=['sample'],\r\n",
    "    \r\n",
    "    # Where to write the data\r\n",
    "    staging_name=\"samples\", \r\n",
    "    connector_name=\"boston_house_price\", \r\n",
    "    \r\n",
    "    # If the table doesn't exists, auto create the schema\r\n",
    "    auto_create_schema=True,\r\n",
    "    flexible_schema=False,\r\n",
    "    \r\n",
    "    # Other options\r\n",
    "#3    async_send=True,\r\n",
    "#    storage_only=True, \r\n",
    "    force=False,\r\n",
    "    gzip=True,\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-9-c6ff1557a1a2>:3: DeprecationWarning: fields_dict will be deprecated, use `data`\n",
      "  staging.send_data(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "provided crosswalk  ['sample']\n",
      "506/506 sent\r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If everything went well on your data ingestion, now you should be able to see your staging on the user interface by clicking on connectors on the left panel, selecting your connector. You can view sample records by clicking on View sample data.\n",
    "\n",
    "__Note__: The same approach can be use to load any tabular data into Carol, just make sure you have your dataset stored on a dataframe and use PyCarol to help on the loading process."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Troubleshooting\n",
    "\n",
    "A couple of well known problems when loading data to Carol are given below:\n",
    "\n",
    "- **Bad crosswalk**: It happens when the columns provided as the crosswalk parameter doesn't holds the unique property for the records.\n",
    "\n",
    "- **Inconsistent schema**: If the staging has been already created before with columns and data types it may result in conflicts when loading new data. In that case it is recomended, whenever it is possible, to drop the previous staging and reload the full data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}